"""
main.py - Orquestra todo o fluxo SBAPA com refatora√ß√£o para biblioteca de extra√ß√£o:

1. L√™ os per√≠odos j√° processados em planilhas/movimentacoes.csv (se existir)
2. Para cada PDF bruto em ./extratos/:
   ‚Ä¢ Verifica que comece com ‚ÄúFale Conosco‚Äù
   ‚Ä¢ Extrai o per√≠odo (‚Äújaneiro/2025‚Äù) da linha ‚ÄúResumo - m√™s/ano‚Äù
   ‚Ä¢ Se o per√≠odo j√° estiver no CSV:
       - Remove o PDF de ./extratos/
       - Pula para o pr√≥ximo
   ‚Ä¢ Caso contr√°rio:
       - Pergunta interativamente faixa de p√°ginas
       - Gera vers√£o aparada em ./input/
3. Se n√£o existir CSV ou houve novos trims ou o usu√°rio solicitar:
   ‚Ä¢ Faz backup do CSV existente em ./last_planilhas/
   ‚Ä¢ Executa extra√ß√£o via extract_all_movements() e write_movements_csv()
4. L√™ o CSV gerado e exibe:
   ‚Ä¢ Todos os per√≠odos em ordem cronol√≥gica
   ‚Ä¢ Lacunas mensais entre eles
   ‚Ä¢ Quais arquivos referenciados n√£o est√£o mais em ./input/
"""

import re
import sys
from datetime import datetime
from pathlib import Path

import pandas as pd
import pdfplumber
from dateutil.relativedelta import relativedelta

from parse_movimentacoes import extract_all_movements, write_movements_csv
from trim import get_num_pages, trim_pdf

# ‚îÄ‚îÄ Config ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
EXTRATO_DIR = Path("extratos")
INPUT_DIR = Path("input")
CSV_PATH = Path("planilhas") / "movimentacoes.csv"
BACKUP_DIR = Path("last_planilhas")

KEY_PHRASE = "Fale Conosco"
RESUMO_RE = re.compile(r"Resumo\s*-\s*([A-Za-z√ß√á]+/\d{4})", re.IGNORECASE)
MONTHS_PT = {
    "janeiro": 1,
    "fevereiro": 2,
    "marco": 3,
    "mar√ßo": 3,
    "abril": 4,
    "maio": 5,
    "junho": 6,
    "julho": 7,
    "agosto": 8,
    "setembro": 9,
    "outubro": 10,
    "novembro": 11,
    "dezembro": 12,
}
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def extract_periodo(pdf_path: Path) -> str:
    """Extrai 'mes/ano' de 'Resumo - m√™s/ano' no PDF, ap√≥s validar KEY_PHRASE."""
    with pdfplumber.open(str(pdf_path)) as pdf:
        first = (pdf.pages[0].extract_text() or "").strip()
        if not first.startswith(KEY_PHRASE):
            raise ValueError("n√£o come√ßa com 'Fale Conosco'")
        for page in pdf.pages:
            txt = page.extract_text() or ""
            m = RESUMO_RE.search(txt)
            if m:
                return m.group(1).lower()
    raise ValueError("linha 'Resumo - m√™s/ano' n√£o encontrada")


def periodo_to_date(periodo: str) -> datetime:
    """Converte 'mes/ano' em datetime no dia 1 para ordena√ß√£o."""
    mes, ano = periodo.split("/")
    num = MONTHS_PT.get(mes)
    if not num:
        raise ValueError(f"M√™s inv√°lido: {mes}")
    return datetime(int(ano), num, 1)


def list_gaps(sorted_periodos: list[str]) -> list[str]:
    """Dada lista ordenada de 'mes/ano', devolve os meses faltantes."""
    if len(sorted_periodos) < 2:
        return []
    dates = [periodo_to_date(p) for p in sorted_periodos]
    gaps = []
    cur = dates[0] + relativedelta(months=1)
    i = 1
    while i < len(dates):
        if cur < dates[i]:
            gaps.append(cur.strftime("%m/%Y"))
            cur += relativedelta(months=1)
        else:
            cur = dates[i] + relativedelta(months=1)
            i += 1
    return gaps


def main() -> None:
    # 1) Preparar pastas
    if not EXTRATO_DIR.is_dir():
        sys.exit("‚ùå Pasta 'extratos/' n√£o encontrada.")
    INPUT_DIR.mkdir(parents=True, exist_ok=True)
    BACKUP_DIR.mkdir(parents=True, exist_ok=True)

    # 2) Carrega per√≠odos j√° processados
    if CSV_PATH.is_file():
        df_exist = pd.read_csv(CSV_PATH, dtype=str, encoding="utf-8")
        processed = set(df_exist["periodo"].dropna().unique())
    else:
        processed = set()

    # 3) Itera sobre PDFs brutos
    pdfs = sorted(EXTRATO_DIR.glob("*.pdf"))
    if not pdfs:
        print("‚ö†Ô∏è  Nenhum PDF em 'extratos/'.")
        return

    new_count = 0
    for pdf in pdfs:
        print(f"\n‚ñ∂Ô∏è  Processando '{pdf.name}'")
        try:
            periodo = extract_periodo(pdf)
        except ValueError as e:
            print(f"   ‚ö†Ô∏è Ignorado: {e}")
            continue

        if periodo in processed:
            print(f"   ‚è≠  Per√≠odo {periodo} j√° processado; removendo PDF.")
            pdf.unlink()
            continue

        total = get_num_pages(pdf)
        print(f"   ‚Üí Per√≠odo: {periodo} | P√°ginas: 1-{total}")

        # Intera√ß√£o para faixa de p√°ginas
        try:
            s = input("   Primeira p√°gina (Enter=1): ").strip()
            start = int(s) if s else 1
            s = input(f"   √öltima p√°gina (Enter={total}): ").strip()
            end = int(s) if s else total
            if not (1 <= start <= end <= total):
                raise ValueError
        except ValueError:
            print("   ‚ùå Faixa inv√°lida; pulando.")
            continue

        trimmed = trim_pdf(pdf, INPUT_DIR, start_page=start, end_page=end)
        print(f"   ‚úÖ Gravado em 'input/{trimmed.name}'")
        processed.add(periodo)
        new_count += 1

    # 4) Decidir se executa extra√ß√£o de movimenta√ß√µes
    # Sempre reexecuta se n√£o houver CSV, ou se houve novos trims.
    run_parser = False
    if not CSV_PATH.is_file():
        run_parser = True
        print("\n‚ñ∂Ô∏è  CSV ausente; executando extra√ß√£o.")
    elif new_count > 0:
        run_parser = True
        print("\n‚ñ∂Ô∏è  Novos PDFs aparados; executando extra√ß√£o.")
    else:
        resp = (
            input("\nNenhum novo extrato aparado. Reexecutar extra√ß√£o? (s/n): ")
            .strip()
            .lower()
        )
        if resp == "s":
            run_parser = True

    if run_parser:
        # 5) Backup do CSV existente
        if CSV_PATH.is_file():
            backup_target = BACKUP_DIR / CSV_PATH.name
            CSV_PATH.replace(backup_target)
            print(f"‚úîÔ∏è  CSV antigo movido para 'last_planilhas/{backup_target.name}'")
        # 6) Extrai e grava CSV
        rows = extract_all_movements(INPUT_DIR)
        if rows:
            write_movements_csv(rows, CSV_PATH)
        else:
            print("‚ö†Ô∏è  Nenhuma transa√ß√£o extra√≠da.")
    else:
        print("\n‚ÑπÔ∏è  Extra√ß√£o n√£o executada; CSV permanece inalterado.")

    # 7) Relat√≥rio final
    if not CSV_PATH.is_file():
        sys.exit("‚ùå CSV n√£o encontrado ap√≥s execu√ß√£o.")

    df = pd.read_csv(CSV_PATH, dtype=str, encoding="utf-8")
    periodos = sorted(df["periodo"].dropna().unique(), key=periodo_to_date)

    print("\nüìÖ Per√≠odos no CSV:")
    for p in periodos:
        print(f"   ‚Ä¢ {p}")

    gaps = list_gaps(periodos)
    if gaps:
        print("\nüöß Lacunas detectadas:")
        for g in gaps:
            print(f"   ‚Ä¢ falta {g}")
    else:
        print("\n‚úÖ Sem lacunas ‚Äî per√≠odos cont√≠guos.")

    arquivos = set(df["arquivo"].dropna().unique())
    missing = [a for a in arquivos if not (INPUT_DIR / a).exists()]
    if missing:
        print("\nüóë PDFs referenciados ausentes em 'input/':")
        for a in missing:
            per = df[df["arquivo"] == a]["periodo"].iloc[0]
            print(f"   ‚Ä¢ {a}  ({per})")
    else:
        print("\n‚úÖ Todos os PDFs referenciados est√£o em 'input/'.")


if __name__ == "__main__":
    main()
